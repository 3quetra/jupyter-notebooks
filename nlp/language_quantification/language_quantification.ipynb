{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the News Analysis\n",
    "\n",
    "Newspapers and their online formats supply the public with the information we need to understand the events occurring in the world around us. From politics to sports, the news keeps us informed, in the loop, and ready to make decisions about how to act in a rapidly changing world.\n",
    "\n",
    "Given the vast amount of news articles in circulation, identifying and organizing articles by topic is a useful activity. This can help you sift through the enormous amount of information out there so you can find the news relevant to your interests, or even allow you to build a news recommendation engine!\n",
    "\n",
    "The News International is the largest English language newspaper in Pakistan, covering local and international news across a variety of sectors. A selection of articles from a Kaggle Dataset of The News International articles (https://www.kaggle.com/asad1m9a9h6mood/news-articles) is provided in the workspace.\n",
    "\n",
    "In this project you will use term frequency-inverse document frequency (tf-idf) to analyze each article’s content and uncover the terms that best describe each article, providing quick insight into each article’s topic.\n",
    "\n",
    "Let’s get started!\n",
    "Tasks\n",
    "12/12 Complete\n",
    "Mark the tasks as complete by checking them off\n",
    "Imports and Data Preparation\n",
    "1.\n",
    "\n",
    "In order to calculate tf-idf scores for the articles in the news dataset, you will need some help from scikit-learn. Begin by importing CountVectorizer, TfidfTransformer, and TfidfVectorizer from sklearn.feature_extraction.text.\n",
    "2.\n",
    "\n",
    "Provided in articles.py is a selection of 10 articles from The News International. Each article, stored as a string, is given as a corpus in the list articles.\n",
    "\n",
    "In script.py, print one of the articles and read its contents.\n",
    "3.\n",
    "\n",
    "Before proceeding, let’s preprocess each article by performing tokenization and lemmatization.\n",
    "\n",
    "Provided in preprocessing.py is a function preprocess_text() that accepts a string as input and returns a preprocessed string.\n",
    "\n",
    "Preprocess each article in articles and store the processed articles in a list called processed_articles.\n",
    "\n",
    "Print out one of the preprocessed articles.\n",
    "Calculate Tf-idf Scores\n",
    "4.\n",
    "\n",
    "You want to begin your analysis by starting off with simple word counts for each article. Initialize a CountVectorizer object assigned to a variable named vectorizer.\n",
    "5.\n",
    "\n",
    "Fit and transform your vectorizer on processed_articles to get the word counts for each article. Save the resulting counts to a variable named counts.\n",
    "\n",
    "After you save the word counts to counts, you will see a DataFrame appear in the browser component. View the DataFrame to see the word counts for each article.\n",
    "6.\n",
    "\n",
    "Now that you have the word counts for each article, let’s convert them into tf-idf scores.\n",
    "\n",
    "Initialize a TfidfTransformer object with keyword argument norm=None saved to a variable transformer.\n",
    "7.\n",
    "\n",
    "Fit and transform your transformer on counts to convert the word counts into tf-idf scores for each article. Save the resulting tf-idf scores to a variable named tfidf_scores_transformed.\n",
    "\n",
    "After you save the tf-idf scores to tfidf_scores_transformed, you will see another DataFrame appear in the browser component. View the DataFrame to see the tf-idf scores for each article.\n",
    "8.\n",
    "\n",
    "Amazing! Now you have your tf-idf scores for each article. You want to confirm, however, that the TfidfTransformer gives the same results as directly using the TfidfVectorizer.\n",
    "\n",
    "Initialize a TfidfVectorizer object with keyword argument norm=None saved to a variable vectorizer.\n",
    "9.\n",
    "\n",
    "Fit and transform your vectorizer on processed_articles to calculate the tf-idf scores for each article in one step. Save the resulting tf-idf scores to a variable named tfidf_scores.\n",
    "\n",
    "After you save the tf-idf scores to tfidf_scores, you will see another DataFrame appear in the browser component. View the DataFrame to see the tf-idf scores for each article.\n",
    "\n",
    "Do the tf-idf scores given by TfidfVectorizer look the same as those given by TfidfTransformer?\n",
    "10.\n",
    "\n",
    "Let’s confirm that the tf-idf scores given by TfidfTransformer and TfidfVectorizer are the same.\n",
    "\n",
    "Paste the following if statement into script.py under the comment “check if tf-idf scores are equal”:\n",
    "\n",
    "if np.allclose(tfidf_scores_transformed.todense(), tfidf_scores.todense()):\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['YES']}))\n",
    "else:\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['No, something is wrong :(']}))\n",
    "\n",
    "You should see that the tf-idf scores are, in fact, the same!\n",
    "Analyze the Results\n",
    "11.\n",
    "\n",
    "A simple way of identifying the “topic” of a document is to label the document with its highest-scoring tf-idf term. While this is a more naive approach than others, it is a quick and easy way of getting insight into the topic of a document.\n",
    "\n",
    "Scroll down to the bottom of script.py, and begin by writing a for loop that iterates a variable i through the values 1 to 10.\n",
    "12.\n",
    "\n",
    "The Pandas Series method .idxmax() is a helpful tool for returning the index of the highest value in a DataFrame column. We will use this method to find the highest scoring tf-idf term for each article.\n",
    "\n",
    "Within the for loop, paste the following code:\n",
    "\n",
    "print(df_tf_idf[[f'Article {i}']].idxmax())\n",
    "\n",
    "On each pass through the for loop, this code will print the index of the term with the highest tf-idf score for that article (from Article 1 to Article 10).\n",
    "\n",
    "Compare the actual text of the articles to the selected term. Do printed terms give you any insight into the topic of the respective articles?\n",
    "\n",
    "Paste the following code within the for loop you just created:\n",
    "\n",
    "print(df_tf_idf[[f'Article {i}']].idxmax())\n",
    "\n",
    "After pasting in the code and running script.py, you should get the following terms as having the highest tf-idf score for each article. While this is a crude approach to topic definition, it is helpful in gaining some quick insight into an articles meaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib3_seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from articles import articles\n",
    "from preprocessing import preprocess_text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "\n",
    "\n",
    "# view article\n",
    "print(articles[0])\n",
    "\n",
    "# preprocess articles\n",
    "processed_articles = [preprocess_text(article) for article in articles]\n",
    "print(processed_articles[0])\n",
    "\n",
    "# initialize and fit CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "\n",
    "\n",
    "# convert counts to tf-idf\n",
    "counts = vectorizer.fit_transform(processed_articles)\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "transformer = TfidfTransformer(norm=None) \n",
    "tfidf_scores_transformed = transformer.fit_transform(counts)\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm=None) \n",
    "tfidf_scores = vectorizer.fit_transform(processed_articles) \n",
    "\n",
    "# check if tf-idf scores are equal\n",
    "if np.allclose(tfidf_scores_transformed.todense(), tfidf_scores.todense()):\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['YES']}))\n",
    "else:\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['No, something is wrong :(']}))\n",
    "\n",
    "# get vocabulary of terms\n",
    "try:\n",
    "  feature_names = vectorizer.get_feature_names()\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# get article index\n",
    "try:\n",
    "  article_index = [f\"Article {i+1}\" for i in range(len(articles))]\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# create pandas DataFrame with word counts\n",
    "try:\n",
    "  df_word_counts = pd.DataFrame(counts.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_word_counts)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# create pandas DataFrame(s) with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores_transformed.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# get highest scoring tf-idf term for each article\n",
    "\n",
    "for i in range(1, 11):\n",
    "  print(df_tf_idf[[f'Article {i}']].idxmax())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
